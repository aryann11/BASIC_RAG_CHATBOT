{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_of_documents =[\n",
    "    \"Pinkerton is the second studio album by the American rock band Weezer, released on September 24, 1996, by DGC Records. \",\n",
    "    \"To better capture their live sound, the band self-produced Pinkerton, creating a darker, more abrasive album than their 1994 debut Weezer.\",\n",
    "    \"The lyrics express loneliness and disillusionment with the rock lifestyle, and reference Japanese culture.\",\n",
    "    \"Pinkerton produced the singles El Scorcho and The Good Life.\",\n",
    "    \"It debuted at number 19 on the Billboard 200.\",\n",
    "    \" For subsequent albums, Weezer returned to more traditional pop songwriting and less personal lyrics.\",\n",
    "    \"In Lebanon, Israeli airstrikes against Hezbollah kill at least 492 people and injure more than 1,600 others.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pinkerton is the second studio album by the American rock band Weezer, released on September 24, 1996, by DGC Records. ',\n",
       " 'To better capture their live sound, the band self-produced Pinkerton, creating a darker, more abrasive album than their 1994 debut Weezer.',\n",
       " 'The lyrics express loneliness and disillusionment with the rock lifestyle, and reference Japanese culture.',\n",
       " 'Pinkerton produced the singles El Scorcho and The Good Life.',\n",
       " 'It debuted at number 19 on the Billboard 200.',\n",
       " ' For subsequent albums, Weezer returned to more traditional pop songwriting and less personal lyrics.',\n",
       " 'In Lebanon, Israeli airstrikes against Hezbollah kill at least 492 people and injure more than 1,600 others.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_of_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query=\"i am a Indian and i live in India\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"india is a country for the indians and for everyone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to find the similarity btw user query and document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert user query to vector \n",
    "from collections import Counter\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'a', 'indian', 'and', 'i', 'live', 'in', 'india']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the character  \n",
    "query_token = user_query.lower().split(\" \")\n",
    "query_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['india',\n",
       " 'is',\n",
       " 'a',\n",
       " 'country',\n",
       " 'for',\n",
       " 'the',\n",
       " 'indians',\n",
       " 'and',\n",
       " 'for',\n",
       " 'everyone']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_token= document.lower().split(\" \")\n",
    "document_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'i': 2,\n",
       "         'am': 1,\n",
       "         'a': 1,\n",
       "         'indian': 1,\n",
       "         'and': 1,\n",
       "         'live': 1,\n",
       "         'in': 1,\n",
       "         'india': 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cal the frequency of the words (TOKENIZE)\n",
    "query_counter =Counter(query_token)\n",
    "query_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'for': 2,\n",
       "         'india': 1,\n",
       "         'is': 1,\n",
       "         'a': 1,\n",
       "         'country': 1,\n",
       "         'the': 1,\n",
       "         'indians': 1,\n",
       "         'and': 1,\n",
       "         'everyone': 1})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_counter =Counter(document_token)\n",
    "document_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query=\"i am a Indian and i live in India\"\n",
    "document = \"india is a country for the indians and for everyone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out common words \n",
    "my_list = []\n",
    "for tokens in query_counter.keys() & document_counter.keys():\n",
    "    my_list.append(query_counter[tokens]* document_counter[tokens])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# got the common vector \n",
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_prod = sum(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_magnitute = math.sqrt(sum(query_counter[tokens] **2 for token in query_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8284271247461903"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_magnitute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_magnitute = math.sqrt(sum(document_counter[tokens] **2 for token in document_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_magnitute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = dot_prod/(query_magnitute*document_magnitute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35355339059327373\n"
     ]
    }
   ],
   "source": [
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.25\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Function to tokenize the sentence into words\n",
    "def tokenize(sentence):\n",
    "    return sentence.lower().split()\n",
    "\n",
    "# Function to compute the cosine similarity between two sentences\n",
    "def cosine_similarity_from_scratch(sent1, sent2):\n",
    "    # Tokenize both sentences\n",
    "    words1 = tokenize(sent1)\n",
    "    words2 = tokenize(sent2)\n",
    "    \n",
    "    # Create a combined vocabulary (unique words from both sentences)\n",
    "    vocab = list(set(words1).union(set(words2)))\n",
    "    \n",
    "    # Create frequency vectors for both sentences\n",
    "    vec1 = [words1.count(word) for word in vocab]\n",
    "    vec2 = [words2.count(word) for word in vocab]\n",
    "    \n",
    "    # Compute the dot product\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    \n",
    "    # Compute the magnitude (L2 norm) of each vector\n",
    "    magnitude_vec1 = np.linalg.norm(vec1)\n",
    "    magnitude_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    # Compute the cosine similarity\n",
    "    if magnitude_vec1 == 0 or magnitude_vec2 == 0:\n",
    "        return 0  # To avoid division by zero, return 0 if any vector has zero magnitude\n",
    "    \n",
    "    cosine_sim = dot_product / (magnitude_vec1 * magnitude_vec2)\n",
    "    \n",
    "    return cosine_sim\n",
    "\n",
    "# Example usage\n",
    "sentence1 = \"I love machine learning.\"\n",
    "sentence2 = \"Machine learning is amazing.\"\n",
    "\n",
    "similarity = cosine_similarity_from_scratch(sentence1, sentence2)\n",
    "print(f\"Cosine Similarity: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_respose(query,corpus):\n",
    "    similarities = []\n",
    "    for doc in corpus:\n",
    "        similarity = cosine_similarity_from_scratch(query , doc )\n",
    "        similarities.append(similarity)\n",
    "    return corpus_of_documents[similarities.index(max(similarities))]\n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pinkerton is the second studio album by the American rock band Weezer, released on September 24, 1996, by DGC Records. ',\n",
       " 'To better capture their live sound, the band self-produced Pinkerton, creating a darker, more abrasive album than their 1994 debut Weezer.',\n",
       " 'The lyrics express loneliness and disillusionment with the rock lifestyle, and reference Japanese culture.',\n",
       " 'Pinkerton produced the singles El Scorcho and The Good Life.',\n",
       " 'It debuted at number 19 on the Billboard 200.',\n",
       " ' For subsequent albums, Weezer returned to more traditional pop songwriting and less personal lyrics.',\n",
       " 'In Lebanon, Israeli airstrikes against Hezbollah kill at least 492 people and injure more than 1,600 others.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_of_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"i want a more abrasive album and funnier part is the creating darker \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'return_respose' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mreturn_respose\u001b[49m(query , corpus_of_documents)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'return_respose' is not defined"
     ]
    }
   ],
   "source": [
    "return_respose(query , corpus_of_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"thats too sad the nuber of people that got killed made my unhappy \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'return_respose' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mreturn_respose\u001b[49m(query , corpus_of_documents)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'return_respose' is not defined"
     ]
    }
   ],
   "source": [
    "return_respose(query , corpus_of_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how u can configure LLM in local system \n",
    "# LLAMA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by using of pretrained model og hugging face (nut not using this )\n",
    "# we r using the oLLama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augument this response using llama 2 model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Response:  Great !  Based  on  your  interest  in  something  advent ur ous ,  I  highly  recommend  going  h ik ing  in  the  mountains .  H ik ing  offers  a  unique  bl end  of  physical  challenge ,  scen ic  beauty ,  and  opportunity  for  self - dis cover y .  The  mountain ous  terrain  provides  a  perfect  setting  for  an  advent ure  that  will  test  your  end urance ,  ag ility ,  and  mental  t ough ness . \n",
      " \n",
      " Im agine  tre kk ing  through  l ush  for ests ,  clim bing  up  rug ged  pe aks ,  and  gaz ing  out  at  bre at ht aking  v istas .  The  fresh  mountain  air  and  the  sound  of  nature  will  inv ig or ate  your  sens es  and  re charge  your  energy  levels .  You ' ll  have  the  opportunity  to  connect  with  nature  and  challenge  yourself  in  new  and  exc iting  ways . \n",
      " \n",
      " So  why  not  la ce  up  your  h ik ing  bo ots ,  grab  a  back pack ,  and  hit  the  tra ils ?  The  mountains  are  waiting  for  you ! \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are a bot that makes recommendations for activities. Your answer will be very short and topic-oriented.\n",
    "This is the recommended activity: {relevant_document}\n",
    "The user input is: {user_input}\n",
    "Compile a recommendation to the user based on the recommended activity and the user input.\n",
    "\"\"\"\n",
    "\n",
    "url = 'http://localhost:11434/api/generate'\n",
    "\n",
    "# Example data for the user_input and relevant_document\n",
    "user_input = \"I want something adventurous\"\n",
    "relevant_document = \"Go hiking in the mountains\"\n",
    "\n",
    "# Prepare the data payload\n",
    "data = {\n",
    "    \"model\": \"llama2\",\n",
    "    \"prompt\": prompt.format(user_input=user_input, relevant_document=relevant_document)\n",
    "}\n",
    "\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "# Send POST request\n",
    "response = requests.post(url, data=json.dumps(data), headers=headers, stream=True)\n",
    "\n",
    "full_response = []\n",
    "\n",
    "# Try block to handle response streaming\n",
    "try:\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            decoded_line = json.loads(line.decode('utf-8'))\n",
    "            full_response.append(decoded_line.get('response', ''))\n",
    "finally:\n",
    "    response.close()\n",
    "\n",
    "# Output the complete response\n",
    "print(\"Full Response:\", \" \".join(full_response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"i want to play cricket with my friends and they r very very good at it  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'return_respose' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m relevant_document \u001b[38;5;241m=\u001b[39m \u001b[43mreturn_respose\u001b[49m(user_input , corpus_of_documents)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'return_respose' is not defined"
     ]
    }
   ],
   "source": [
    "relevant_document = return_respose(user_input , corpus_of_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
